---
title: "Predicting AirBnB Rental Rates"
author: "Trevor Isaacson, Jonathan Olavarria, Jasmine DeMeyer"
date: "12/10/2021"
output: pdf_document
---

```{r setup, include=FALSE, echo = FALSE}
set.seed(445)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.width=5, fig.height=3) 
library(ggplot2)
library(tidyverse)
library(tidyr)
library(e1071)
library(rmarkdown)
library(glmnet)
library(knitr)
library(leaps)
library(tree)
library(dplyr)
library(caret)
library(gbm)
library(randomForest)
library(GGally)
library(pls)
library(splines)
library(boot)
```

```{r}
original_df = read.csv("training_data.csv")
```

```{r}
training_df = original_df %>% 
  mutate(price = log_price)  %>%
  select(-c(id, amenities, description, thumbnail_url, zipcode, name, neighbourhood, X, log_price)) %>%
  mutate(first_review = as.Date(original_df$first_review, format = "%Y-%m-%d")) %>%
  mutate(last_review = as.Date(original_df$last_review, format = "%Y-%m-%d")) %>%
  mutate(host_since = as.Date(original_df$host_since, format = "%Y-%m-%d")) %>%
  mutate(host_response_rate = as.numeric(sub("%", "", original_df$host_response_rate))/100)

training_df = training_df %>%
  mutate(first_review_year = as.Date(cut(training_df$first_review, "year"))) %>%
  mutate(last_review_year = as.Date(cut(training_df$last_review, "year"))) %>%
  mutate(host_since_year = as.Date(cut(training_df$host_since, "year"))) %>%
  mutate(host_has_profile_pic = replace(host_has_profile_pic, host_has_profile_pic == "", "f")) %>%   # eliminate blank values
  mutate(host_identity_verified = replace(host_identity_verified, host_identity_verified == "", "f"))  # eliminate blank values

training_df = training_df %>%
  mutate(first_review_year = as.numeric(format(first_review_year, format = "%Y"))) %>%
  mutate(last_review_year = as.numeric(format(last_review_year, format = "%Y"))) %>%
  mutate(host_since_year = as.numeric(format(host_since_year, format = "%Y")))

training_df = training_df %>%
  mutate(first_review_year = factor(ifelse(first_review_year <= 2014, "Less2014", "Greater2014"))) %>%
  mutate(last_review_year = factor(ifelse(last_review_year <= 2014, "Less2014", "Greater2014"))) %>%
  mutate(host_since_year = factor(ifelse(host_since_year <= 2014, "Less2014", "Greater2014"))) %>%
  mutate(host_response_rate  = if_else(is.na(host_response_rate), 0, host_response_rate)) %>%
  mutate(cleaning_fee = as.factor(cleaning_fee))

training_df = training_df[complete.cases(training_df), ]

training_df <- training_df %>%
  filter(property_type != "Chalet") %>%
  filter(property_type != "Island") %>%
  filter(property_type != "Tent") %>%
  filter(property_type != "Treehouse") %>%
  filter(property_type != "Yurt") %>%
  filter(property_type != "Hut") %>%
  filter(property_type != "Train") %>%
  filter(property_type != "Vacation home") %>%
  select(-c(first_review, last_review, host_since))
```

**Introduction:**     





**The Data:**
As a company, AirBnB is very open and transparent with the data they collect about their rental properties.  They provide data about rental spaces in their system for cities and countries all over the world.  Because of this, we were able to find a large dataset on Kaggle with AirBnB listings in major US cities including New York City, Los Angeles, San Francisco and others.  The dataset available on Kaggle has over 74,000 entries and was used as a competition a few years ago.  For the sake of time and processing, we trimmed our training data to about 17,500 entries and our test data to about 5,000 entries.  We did this by taking a random sample of the provided training data.  This allowed for easier access and faster processing while maintaining a large amount of data and individual AirBnB listings.  

The original dataset contained 30 variables about each listing.  Due to high correlations and lack of relevancy, our final dataset consisted of twenty-two variables.  Those twenty-two variables can be split into four categories: property, location, host and host reviews.  

Property includes:

  - price: listing price    
      - Note: Because the original price data is very heavily skewed, we needed to log transform the prices.  This gives a normal distribution of prices allowing for better prediction capabilities and interpretability.

```{r fig.width=5, fig.height=3,  fig.show='hold', out.width="50%"}
ggplot(data = training_df) +
  geom_histogram(aes(exp(price)), bins = 50) +
  ggtitle("Listing Price ($)") + 
  geom_vline(xintercept = median(training_df$price), color = "blue", lty = 2) + xlab("price")

ggplot(data = training_df) +
  geom_histogram(aes(price), bins = 25) +
  ggtitle("Log of Listing Price ($)") + 
  geom_vline(xintercept = median(training_df$price), color = "blue", lty = 2) + xlab("log(price)")
```   

  - property_type: defines the type of property listed
      - There are 21 different types ranging from apartments, houses, and condos to boats, cabins, hostels and even castles
  
  - room_type: defines type of rental within the property
      - Includes entire home/apt, private room and shared room
  
  - accommodates: number of people the property can comfortably accommodate
  
  - bedrooms: number of bedrooms within the property
  
  - beds: number of beds within the property
  
  - bed_type: type of bed available
      - This includes a Real Bed, Futon, Pull-out Sofa,	Airbed or Couch
      - Only 463 listings have something other than a Real Bed
  
  - bathrooms: number of bathrooms within the property
  
```{r echo = FALSE, message=FALSE, fig.width=5, fig.height=3,  fig.show='hold', out.width="50%"}
training_df %>%
  group_by(accommodates) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  ggplot() + 
  geom_point(aes(x = accommodates, y = Total)) + 
  geom_line(aes(x = accommodates, y = Total)) +
  ggtitle("Accommodates Distribution") + scale_x_continuous(breaks = c(0:16))

training_df %>%
  group_by(beds) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  ggplot() + 
  geom_point(aes(x = beds, y = Total)) + 
  geom_line(aes(x = beds, y = Total)) +
  ggtitle("Beds Distribution") + scale_x_continuous(breaks = c(0:20))
```

```{r echo = FALSE, message=FALSE, fig.width=5, fig.height=3,  fig.show='hold', out.width="50%"}
training_df %>%
  group_by(bedrooms) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  ggplot() +
  geom_point(aes(x = bedrooms, y = Total)) + 
  geom_line(aes(x = bedrooms, y = Total)) +
  ggtitle("Bedrooms Distribution") + scale_x_continuous(breaks = c(0:10))

training_df %>%
  group_by(bathrooms) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  ggplot() +
  geom_point(aes(x = bathrooms, y = Total)) + 
  geom_line(aes(x = bathrooms, y = Total)) +
  ggtitle("Bathrooms Distribution") + scale_x_continuous(breaks = c(0:8))
```
  
Location includes:

  - city: Location of listing
  
  - latitude and longitude: latitude and longitude coordinates of the listing
  
```{r echo = FALSE, message=FALSE, fig.width=5, fig.height=3,  fig.show='hold', out.width="50%"}
training_df %>%
  group_by(city) %>%
  ggplot() + geom_bar(aes(city)) + 
  ggtitle("City Distribution")

latlong = training_df[training_df$longitude > -73, ]
ggplot(data = latlong) +
  geom_point(aes(x = longitude, y = latitude, color = city)) +
  ggtitle("Listings in Boston")
```
  
Host includes: 

  - cancellation_policy: strictness of cancellation policy set by the host
      - Levels include strict, moderate, flexible, super_strict_30	and super_strict_60
  
  - cleaning_fee: TRUE/FALSE determines if host charges a cleaning fee
  
  - host_has_profile_pic: TRUE/FALSE determines if the host has uploaded a picture to their profile
  
  - host_identify_verified: TRUE/FALSE determines if the host's identity has been verified by AirBnB
  
  - instant_bookable: TRUE/FALSE determines if the property can be booked in short notice
  
  - host_response_rate: how often does the host reply to potential clients?

```{r echo = FALSE, message=FALSE, fig.width=5, fig.height=3,  fig.show='hold', out.width="33%"}
training_df %>%
  group_by(cancellation_policy) %>%
  ggplot() + geom_bar(aes(cancellation_policy)) + 
  ggtitle("Cancellation Policy")

training_df %>%
  group_by(cleaning_fee) %>%
  ggplot() + geom_bar(aes(cleaning_fee)) + 
  ggtitle("Cleaning Fee?")

training_df %>%
  group_by(host_has_profile_pic) %>%
  ggplot() + geom_bar(aes(host_has_profile_pic)) + 
  ggtitle("Profile Pic?")
```


```{r echo = FALSE, message=FALSE, fig.width=5, fig.height=3,  fig.show='hold', out.width="33%"}
training_df %>%
  group_by(host_identity_verified) %>%
  ggplot() + geom_bar(aes(host_identity_verified)) + 
  ggtitle("Identify Verified?")

training_df %>%
  group_by(instant_bookable) %>%
  ggplot() + geom_bar(aes(instant_bookable)) + 
  ggtitle("Instant Bookable?")
```


Host Reviews:

  - number_of_reviews: Number of reviews the host has received
  
  - review_scores_rating: average review rating for the host and property
  
  - first_review_year: year of the first review
  
  - last_review_year: year of most recent review
  
  - host_since_year: year the property was first listed on AirBnB
  
Conclude predictors


**Models**   
There are have a lot of machine learning methods discussed this past semester and we wanted to incorporate some of our favorites into our research.  Thus, we have included linear regression, splines, general additive models, PCR, PLS, trees, bagging, random forests and bagging.   
```{r}
trn = sample(seq_len(nrow(training_df)), 9000)
training = training_df[trn, ]
testing = training_df[-trn, ]
```
In order to both train and test using the training data file, we needed to split the 17,500 total observations into roughly a 50/50 split.  To do this, we took a random sample of 9000 observations and made that the training set.  From now on, this random sample with be referred to as the training set. The remaining 7500 observations became our testing set for determining the mean squared error of each model.  This is will be referred to as the testing set.  

**Regression**        
To begin, we started with a simple multiple linear regression model.  We wanted to give ourselves a baseline mean squared error value and because linear regression is the easiest to apply and interpret, we determined this was the best place to start.  The model was fit using all twenty-two variables and the training set.  

```{r out.width="33%", echo=FALSE}
linear = lm(price ~ ., data = training)
linear_predict = predict(linear, newdata = testing, type = "response")
MSE_testing = (testing$price - linear_predict)^2
summaryLinear = summary(linear)
print(paste("R^2:", round(summaryLinear$r.squared, 3), ", Adjusted R^2: ", round(summaryLinear$adj.r.squared, 3)))
print(paste("MSE of Testing Set: ", round(mean(MSE_testing), 4)))
```

```{r warning = FALSE}
n = 107
results_LOOCV = c()
for(i in seq_len(n)){
  trn <- seq_len(n) != i
  
  #fit model
  l = lm(price ~ ., data = training_df[trn, ])
  
  # predict on validation set
  pred = predict(l, training_df[!trn, ])
  
  # estimate test MSE
  true_price = training_df[!trn, ]$price
  
  results_LOOCV[i] = (true_price - pred)^2
}

print(paste("Leave One Out Cross Validation: ", round(mean(results_LOOCV), 4)))
```

As shown in the results above, our linear regression model was able to set a good baseline for future methods with a mean squared error of 0.1652.  With our linear regression model, we also applied some cross validation.  For Leave One Out Cross Validation, we achieved a mean squared error 0.1829.   


**Regression Splines/Generalized Additive Models:**           



**PCR and PLS**       



**Trees**       



**Bagging**



**Random Forests**



**Boosting**




**Results**            




**City Prediction**



\newpage

**References:**













