---
title: "Predicting AirBnB Rental Rates"
author: "Trevor Isaacson, Jonathan Olavarria, Jasmine DeMeyer"
date: "12/10/2021"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE, echo = FALSE}
set.seed(445)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.width=5, fig.height=3) 
knitr::opts_chunk$set(message = FALSE)
library(ggplot2)
library(tidyverse)
library(tidyr)
library(e1071)
library(rmarkdown)
library(glmnet)
library(knitr)
library(leaps)
library(tree)
library(dplyr)
library(caret)
library(gbm)
library(randomForest)
library(GGally)
```

```{r}
original_df = read.csv("training_data.csv")
nrow(original_df)
head(original_df)
```

probably don't want the individual id of each place, its website url, description, amenities, name, zipcode (we have lat/long and city) and converted log_price to price
```{r}
training_df = original_df %>% 
  mutate(price = log_price)  %>%
  select(-c(id, amenities, description, thumbnail_url, zipcode, name, eighbourhood, X, log_price)) %>%
  mutate(first_review = as.Date(original_df$first_review, format = "%Y-%m-%d")) %>%
  mutate(last_review = as.Date(original_df$last_review, format = "%Y-%m-%d")) %>%
  mutate(host_since = as.Date(original_df$host_since, format = "%Y-%m-%d")) %>%
  mutate(host_response_rate = as.numeric(sub("%", "", original_df$host_response_rate))/100)
```

```{r}
head(training_df)
```

```{r}
# update 3 date columns to track the start of the week instead of the individual date
# create 3 new columns to track dates in the form of month instead of individual date
training_df = training_df %>%
  mutate(first_review_year = as.Date(cut(training_df$first_review, "year"))) %>%
  mutate(last_review_year = as.Date(cut(training_df$last_review, "year"))) %>%
  mutate(host_since_year = as.Date(cut(training_df$host_since, "year"))) %>%
  mutate(host_has_profile_pic = replace(host_has_profile_pic, host_has_profile_pic == "", "f")) %>%   # eliminate blank values
  mutate(host_identity_verified = replace(host_identity_verified, host_identity_verified == "", "f"))  # eliminate blank values

training_df = training_df %>%
  mutate(first_review_year = as.numeric(format(first_review_year, format = "%Y"))) %>%
  mutate(last_review_year = as.numeric(format(last_review_year, format = "%Y"))) %>%
  mutate(host_since_year = as.numeric(format(host_since_year, format = "%Y")))

training_df = training_df %>%
  mutate(first_review_year = factor(ifelse(first_review_year <= 2014, "Less2014", "Greater2014"))) %>%
  mutate(last_review_year = factor(ifelse(last_review_year <= 2014, "Less2014", "Greater2014"))) %>%
  mutate(host_since_year = factor(ifelse(host_since_year <= 2014, "Less2014", "Greater2014"))) %>%
  mutate(host_response_rate  = if_else(is.na(host_response_rate), 0, host_response_rate))
```

```{r}
# these appear in training set and not testing set so I took them out
training_df <- training_df %>%
  filter(property_type != "Chalet") %>%
  filter(property_type != "Island") %>%
  filter(property_type != "Tent") %>%
  filter(property_type != "Treehouse") %>%
  filter(property_type != "Yurt") %>%
  filter(property_type != "Hut") %>%
  filter(property_type != "Train") %>%
  filter(property_type != "Vacation home")

head(training_df)
```

# Variable Descriptions:
## Price
```{r}
ggplot(data = training_df) +
  geom_histogram(aes(price), bins = 25) +
  ggtitle("Listing Price ($)") + 
  geom_vline(xintercept = median(training_df$price), color = "blue", lty = 2)

```

## Property Type
```{r}
training_df %>%
  group_by(property_type) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  kable()

training_df %>%
  group_by(room_type) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  kable()
```

## City
```{r}
training_df %>%
  group_by(city) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total))

# latitude and longitude
ggplot(data = training_df) +
  geom_point(aes(x = longitude, y = latitude, color = city)) +
  ggtitle("Latitude and Longitude")

```



## Property Details
```{r}
training_df %>%
  group_by(accommodates) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  kable()

training_df %>%
  group_by(bedrooms) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  kable()

training_df %>%
  group_by(bathrooms) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  kable()

training_df %>%
  group_by(bed_type) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  kable()

```

## Host details
```{r}
training_df %>%
  group_by(host_has_profile_pic) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  kable()

training_df %>%
  group_by(host_identity_verified) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  kable()

training_df %>%
  group_by(instant_bookable) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  kable()

training_df %>%
  group_by(cancellation_policy) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) 

training_df %>%
  group_by(host_response_rate) %>%
  summarise(Total = n()) %>%
  arrange(desc(Total)) %>%
  kable()
```


## Variable Selection?
Should we first choose we variables should be included in everybody's models or have everybody make their two models and then variable select based on the best model they found? 

Correlation Plot?
```{r}
head(training_df)
# Original df
ggcorr(original_df)
```







## Models
Do we want to split the training_data in half and make one half training and the other half available to use for CV testing and then the testing_data.csv is used for the final model predictions since it doesn't have a price column?
```{r}
trn = sample(seq_len(nrow(training_df)), 9000)
training = training_df[trn, ]
testing = training_df[-trn, ]
str(testing)
```

Baseline: Linear Regression
```{r}
linear = lm(price ~ ., data = training)
summary(linear)
```

```{r}
linear_predict = predict(linear, newdata = testing, type = "response")
MSE_testing = (testing$price - linear_predict)^2
print(paste("MSE of Testing Set: ", mean(MSE_testing)))
```

Leave One Out Cross Validation on Linear Regression Model:
```{r warning = FALSE}
n = 107
results_LOOCV = c()
for(i in seq_len(n)){
  trn <- seq_len(n) != i
  
  #fit model
  l = lm(price ~ ., data = training_df[trn, ])
  
  # predict on validation set
  pred = predict(l, training_df[!trn, ])
  
  # estimate test MSE
  true_price = training_df[!trn, ]$price
  
  results_LOOCV[i] = (true_price - pred)^2
}

print(paste("Leave One Out Cross Validation: ", round(mean(results_LOOCV), 2)))
```

k-Fold Cross Validation on Linear Regression Model:
```{r warning = FALSE}
k = 10
folds = sample(seq_len(k), nrow(training_df) , replace = TRUE)
results_kfold = c()
for(i in seq_len(k)){
  trn <- folds != i
  
  #fit model
  l = lm(price ~ ., data = training_df[trn, ])
  
  # predict on validation set
  pred = predict(l, training_df[!trn, ])
  
  # estimate test MSE
  true_price = training_df[!trn, ]$price
  
  results_kfold[i] = (true_price - pred)^2
}

print(paste("k-fold Cross Validation: ", round(mean(results_kfold), 2)))
```


JJ: PCR and PLS


Jasmine: Regression Splines/Generalized Additive Models



Trevor: Regression Trees/Bagging/Random Forests
```{r} 
# fit regression tree
initial_tree = tree(price ~ ., data = training)
summary(initial_tree)
plot(initial_tree)
text(initial_tree, cex = 0.65, digits = 4, pretty = 0)
initial_tree
```


```{r}
initial_predict = predict(initial_tree, newdata = testing)
postResample(initial_predict, testing$price)

# cross validation
initial_cv = cv.tree(initial_tree)
ggplot() +
  geom_point(aes(x = initial_cv$size, y = initial_cv$dev)) + 
  geom_line(aes(x = initial_cv$size, y = initial_cv$dev)) + 
  ylab("CV Error Rate") + xlab("Size") + ggtitle("CV Classification Error Rate")

# pruned by CV
prune_initial <- prune.tree(initial_tree, best = 8)
plot(prune_initial)
text(prune_initial, cex = 0.65, digits = 4, pretty = 0)
```

Bagging/Random Forests: 
```{r}
bag_fit <- randomForest(price ~ property_type + room_type + accommodates + bathrooms + bed_type + cancellation_policy + cleaning_fee + city + host_has_profile_pic + host_identity_verified  + host_response_rate + instant_bookable + latitude + longitude + number_of_reviews + review_scores_rating + bedrooms + beds + first_review_year + last_review_year + host_since_year, data = training, importance = FALSE)
```

```{r}
data.frame(bag_fit$importance)%>%
  mutate(variable = rownames(bag_fit$importance)) ## %>%
  ## mutate(variable = factor(variable, levels = variable[order(MeanDecreaseGini)]))  ## trick to plot variable by descending Gini
  # ggplot() +
  # geom_point(aes(MeanDecreaseGini, variable))
```




Boosting:
```{r}


```






## Final Model







## Results
Use best model and predict prices for a certain city and plot based on price (heatmap?)










